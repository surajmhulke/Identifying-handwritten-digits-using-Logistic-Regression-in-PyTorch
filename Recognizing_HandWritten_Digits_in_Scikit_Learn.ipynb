{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "B3MGXo4FyJjS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST Dataset (Images and Labels)\n",
        "train_dataset = dsets.MNIST(root ='./data',\n",
        "\t\t\t\t\t\t\ttrain = True,\n",
        "\t\t\t\t\t\t\ttransform = transforms.ToTensor(),\n",
        "\t\t\t\t\t\t\tdownload = True)\n",
        "batch_size = 50\n",
        "test_dataset = dsets.MNIST(root ='./data',\n",
        "\t\t\t\t\t\ttrain = False,\n",
        "\t\t\t\t\t\ttransform = transforms.ToTensor())\n",
        "\n",
        "# Dataset Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "\t\t\t\t\t\t\t\t\t\tbatch_size = batch_size,\n",
        "\t\t\t\t\t\t\t\t\t\tshuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "\t\t\t\t\t\t\t\t\t\tbatch_size = batch_size,\n",
        "\t\t\t\t\t\t\t\t\t\tshuffle = False)\n"
      ],
      "metadata": {
        "id": "fhXsZ-d3yaqF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper Parameters\n",
        "input_size = 784\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n"
      ],
      "metadata": {
        "id": "ofe82xQKybzy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "\tdef __init__(self, input_size, num_classes):\n",
        "\t\tsuper(LogisticRegression, self).__init__()\n",
        "\t\tself.linear = nn.Linear(input_size, num_classes)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tout = self.linear(x)\n",
        "\t\treturn out\n"
      ],
      "metadata": {
        "id": "InOL4Kc8yddi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(input_size, num_classes)\n"
      ],
      "metadata": {
        "id": "dkyoDLBryfbB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n"
      ],
      "metadata": {
        "id": "F4zFpJxXygoT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the Model\n",
        "for epoch in range(num_epochs):\n",
        "\tfor i, (images, labels) in enumerate(train_loader):\n",
        "\t\timages = Variable(images.view(-1, 28 * 28))\n",
        "\t\tlabels = Variable(labels)\n",
        "\n",
        "\t\t# Forward + Backward + Optimize\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\toutputs = model(images)\n",
        "\t\tloss = criterion(outputs, labels)\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\n",
        "\t\tif (i + 1) % 100 == 0:\n",
        "\t\t\tprint('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f'\n",
        "\t\t\t\t% (epoch + 1, num_epochs, i + 1,\n",
        "\t\t\t\t\tlen(train_dataset) // batch_size, loss.data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "NwOct3PByiB0",
        "outputId": "be040d70-a199-428a-dabc-b5d1202ec8b7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [ 1/ 5], Step: [ 100/ 600], Loss: 2.1327\n",
            "Epoch: [ 1/ 5], Step: [ 200/ 600], Loss: 2.0336\n",
            "Epoch: [ 1/ 5], Step: [ 300/ 600], Loss: 1.9775\n",
            "Epoch: [ 1/ 5], Step: [ 400/ 600], Loss: 1.8696\n",
            "Epoch: [ 1/ 5], Step: [ 500/ 600], Loss: 1.7381\n",
            "Epoch: [ 1/ 5], Step: [ 600/ 600], Loss: 1.7125\n",
            "Epoch: [ 1/ 5], Step: [ 700/ 600], Loss: 1.6234\n",
            "Epoch: [ 1/ 5], Step: [ 800/ 600], Loss: 1.6167\n",
            "Epoch: [ 1/ 5], Step: [ 900/ 600], Loss: 1.4918\n",
            "Epoch: [ 1/ 5], Step: [ 1000/ 600], Loss: 1.4142\n",
            "Epoch: [ 1/ 5], Step: [ 1100/ 600], Loss: 1.4807\n",
            "Epoch: [ 1/ 5], Step: [ 1200/ 600], Loss: 1.4734\n",
            "Epoch: [ 2/ 5], Step: [ 100/ 600], Loss: 1.4078\n",
            "Epoch: [ 2/ 5], Step: [ 200/ 600], Loss: 1.3097\n",
            "Epoch: [ 2/ 5], Step: [ 300/ 600], Loss: 1.4305\n",
            "Epoch: [ 2/ 5], Step: [ 400/ 600], Loss: 1.1940\n",
            "Epoch: [ 2/ 5], Step: [ 500/ 600], Loss: 1.1231\n",
            "Epoch: [ 2/ 5], Step: [ 600/ 600], Loss: 1.1887\n",
            "Epoch: [ 2/ 5], Step: [ 700/ 600], Loss: 1.2000\n",
            "Epoch: [ 2/ 5], Step: [ 800/ 600], Loss: 1.2827\n",
            "Epoch: [ 2/ 5], Step: [ 900/ 600], Loss: 1.0901\n",
            "Epoch: [ 2/ 5], Step: [ 1000/ 600], Loss: 1.2144\n",
            "Epoch: [ 2/ 5], Step: [ 1100/ 600], Loss: 1.1319\n",
            "Epoch: [ 2/ 5], Step: [ 1200/ 600], Loss: 0.9549\n",
            "Epoch: [ 3/ 5], Step: [ 100/ 600], Loss: 1.0599\n",
            "Epoch: [ 3/ 5], Step: [ 200/ 600], Loss: 1.0000\n",
            "Epoch: [ 3/ 5], Step: [ 300/ 600], Loss: 1.1094\n",
            "Epoch: [ 3/ 5], Step: [ 400/ 600], Loss: 0.9460\n",
            "Epoch: [ 3/ 5], Step: [ 500/ 600], Loss: 0.9049\n",
            "Epoch: [ 3/ 5], Step: [ 600/ 600], Loss: 1.0086\n",
            "Epoch: [ 3/ 5], Step: [ 700/ 600], Loss: 1.0806\n",
            "Epoch: [ 3/ 5], Step: [ 800/ 600], Loss: 0.9107\n",
            "Epoch: [ 3/ 5], Step: [ 900/ 600], Loss: 0.8483\n",
            "Epoch: [ 3/ 5], Step: [ 1000/ 600], Loss: 0.8997\n",
            "Epoch: [ 3/ 5], Step: [ 1100/ 600], Loss: 1.0020\n",
            "Epoch: [ 3/ 5], Step: [ 1200/ 600], Loss: 0.9539\n",
            "Epoch: [ 4/ 5], Step: [ 100/ 600], Loss: 1.0002\n",
            "Epoch: [ 4/ 5], Step: [ 200/ 600], Loss: 1.0690\n",
            "Epoch: [ 4/ 5], Step: [ 300/ 600], Loss: 0.7204\n",
            "Epoch: [ 4/ 5], Step: [ 400/ 600], Loss: 0.8605\n",
            "Epoch: [ 4/ 5], Step: [ 500/ 600], Loss: 0.9070\n",
            "Epoch: [ 4/ 5], Step: [ 600/ 600], Loss: 0.9304\n",
            "Epoch: [ 4/ 5], Step: [ 700/ 600], Loss: 0.8130\n",
            "Epoch: [ 4/ 5], Step: [ 800/ 600], Loss: 0.7922\n",
            "Epoch: [ 4/ 5], Step: [ 900/ 600], Loss: 0.8024\n",
            "Epoch: [ 4/ 5], Step: [ 1000/ 600], Loss: 0.8400\n",
            "Epoch: [ 4/ 5], Step: [ 1100/ 600], Loss: 0.8124\n",
            "Epoch: [ 4/ 5], Step: [ 1200/ 600], Loss: 0.8905\n",
            "Epoch: [ 5/ 5], Step: [ 100/ 600], Loss: 0.7574\n",
            "Epoch: [ 5/ 5], Step: [ 200/ 600], Loss: 0.8195\n",
            "Epoch: [ 5/ 5], Step: [ 300/ 600], Loss: 0.7503\n",
            "Epoch: [ 5/ 5], Step: [ 400/ 600], Loss: 0.8072\n",
            "Epoch: [ 5/ 5], Step: [ 500/ 600], Loss: 0.6906\n",
            "Epoch: [ 5/ 5], Step: [ 600/ 600], Loss: 0.6157\n",
            "Epoch: [ 5/ 5], Step: [ 700/ 600], Loss: 0.6567\n",
            "Epoch: [ 5/ 5], Step: [ 800/ 600], Loss: 0.7662\n",
            "Epoch: [ 5/ 5], Step: [ 900/ 600], Loss: 0.7824\n",
            "Epoch: [ 5/ 5], Step: [ 1000/ 600], Loss: 0.8043\n",
            "Epoch: [ 5/ 5], Step: [ 1100/ 600], Loss: 0.6856\n",
            "Epoch: [ 5/ 5], Step: [ 1200/ 600], Loss: 0.6119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the Model\n",
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_loader:\n",
        "\timages = Variable(images.view(-1, 28 * 28))\n",
        "\toutputs = model(images)\n",
        "\t_, predicted = torch.max(outputs.data, 1)\n",
        "\ttotal += labels.size(0)\n",
        "\tcorrect += (predicted == labels).sum()\n",
        "\n",
        "print('Accuracy of the model on the 10000 test images: % d %%' % (\n",
        "\t\t\t100 * correct / total))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "c7NHAiQuyjO0",
        "outputId": "788d89ac-e77c-46c8-9ece-dea28b582b4f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the 10000 test images:  85 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "# MNIST Dataset (Images and Labels)\n",
        "train_dataset = dsets.MNIST(root ='./data',\n",
        "\t\t\t\t\t\t\ttrain = True,\n",
        "\t\t\t\t\t\t\ttransform = transforms.ToTensor(),\n",
        "\t\t\t\t\t\t\tdownload = True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root ='./data',\n",
        "\t\t\t\t\t\ttrain = False,\n",
        "\t\t\t\t\t\ttransform = transforms.ToTensor())\n",
        "\n",
        "# Dataset Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "\t\t\t\t\t\t\t\t\t\tbatch_size = batch_size,\n",
        "\t\t\t\t\t\t\t\t\t\tshuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "\t\t\t\t\t\t\t\t\t\tbatch_size = batch_size,\n",
        "\t\t\t\t\t\t\t\t\t\tshuffle = False)\n",
        "\n",
        "# Hyper Parameters\n",
        "input_size = 784\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Model\n",
        "class LogisticRegression(nn.Module):\n",
        "\tdef __init__(self, input_size, num_classes):\n",
        "\t\tsuper(LogisticRegression, self).__init__()\n",
        "\t\tself.linear = nn.Linear(input_size, num_classes)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tout = self.linear(x)\n",
        "\t\treturn out\n",
        "\n",
        "\n",
        "model = LogisticRegression(input_size, num_classes)\n",
        "\n",
        "# Loss and Optimizer\n",
        "# Softmax is internally computed.\n",
        "# Set parameters to be updated.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "# Training the Model\n",
        "for epoch in range(num_epochs):\n",
        "\tfor i, (images, labels) in enumerate(train_loader):\n",
        "\t\timages = Variable(images.view(-1, 28 * 28))\n",
        "\t\tlabels = Variable(labels)\n",
        "\n",
        "\t\t# Forward + Backward + Optimize\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\toutputs = model(images)\n",
        "\t\tloss = criterion(outputs, labels)\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\n",
        "\t\tif (i + 1) % 100 == 0:\n",
        "\t\t\tprint('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f'\n",
        "\t\t\t\t% (epoch + 1, num_epochs, i + 1,\n",
        "\t\t\t\t\tlen(train_dataset) // batch_size, loss.data))\n",
        "\n",
        "# Test the Model\n",
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_loader:\n",
        "\timages = Variable(images.view(-1, 28 * 28))\n",
        "\toutputs = model(images)\n",
        "\t_, predicted = torch.max(outputs.data, 1)\n",
        "\ttotal += labels.size(0)\n",
        "\tcorrect += (predicted == labels).sum()\n",
        "\n",
        "print('Accuracy of the model on the 10000 test images: % d %%' % (\n",
        "\t\t\t100 * correct / total))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KLrjqCeM2UZm",
        "outputId": "d430c8c6-9d78-4504-c6a9-5a2dd64bf096"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [ 1/ 5], Step: [ 100/ 600], Loss: 2.2391\n",
            "Epoch: [ 1/ 5], Step: [ 200/ 600], Loss: 2.1111\n",
            "Epoch: [ 1/ 5], Step: [ 300/ 600], Loss: 2.0845\n",
            "Epoch: [ 1/ 5], Step: [ 400/ 600], Loss: 1.9413\n",
            "Epoch: [ 1/ 5], Step: [ 500/ 600], Loss: 1.8801\n",
            "Epoch: [ 1/ 5], Step: [ 600/ 600], Loss: 1.8433\n",
            "Epoch: [ 2/ 5], Step: [ 100/ 600], Loss: 1.7449\n",
            "Epoch: [ 2/ 5], Step: [ 200/ 600], Loss: 1.6715\n",
            "Epoch: [ 2/ 5], Step: [ 300/ 600], Loss: 1.6423\n",
            "Epoch: [ 2/ 5], Step: [ 400/ 600], Loss: 1.5381\n",
            "Epoch: [ 2/ 5], Step: [ 500/ 600], Loss: 1.5653\n",
            "Epoch: [ 2/ 5], Step: [ 600/ 600], Loss: 1.4361\n",
            "Epoch: [ 3/ 5], Step: [ 100/ 600], Loss: 1.5050\n",
            "Epoch: [ 3/ 5], Step: [ 200/ 600], Loss: 1.3620\n",
            "Epoch: [ 3/ 5], Step: [ 300/ 600], Loss: 1.3850\n",
            "Epoch: [ 3/ 5], Step: [ 400/ 600], Loss: 1.3414\n",
            "Epoch: [ 3/ 5], Step: [ 500/ 600], Loss: 1.3932\n",
            "Epoch: [ 3/ 5], Step: [ 600/ 600], Loss: 1.2719\n",
            "Epoch: [ 4/ 5], Step: [ 100/ 600], Loss: 1.2336\n",
            "Epoch: [ 4/ 5], Step: [ 200/ 600], Loss: 1.2778\n",
            "Epoch: [ 4/ 5], Step: [ 300/ 600], Loss: 1.1559\n",
            "Epoch: [ 4/ 5], Step: [ 400/ 600], Loss: 1.1081\n",
            "Epoch: [ 4/ 5], Step: [ 500/ 600], Loss: 1.1411\n",
            "Epoch: [ 4/ 5], Step: [ 600/ 600], Loss: 1.0666\n",
            "Epoch: [ 5/ 5], Step: [ 100/ 600], Loss: 1.1531\n",
            "Epoch: [ 5/ 5], Step: [ 200/ 600], Loss: 1.0794\n",
            "Epoch: [ 5/ 5], Step: [ 300/ 600], Loss: 0.9705\n",
            "Epoch: [ 5/ 5], Step: [ 400/ 600], Loss: 1.0563\n",
            "Epoch: [ 5/ 5], Step: [ 500/ 600], Loss: 1.0063\n",
            "Epoch: [ 5/ 5], Step: [ 600/ 600], Loss: 0.9746\n",
            "Accuracy of the model on the 10000 test images:  82 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ztRrmBbK2VGW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}